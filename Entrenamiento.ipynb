{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77eddf67",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecde7648",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b579c4",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26193d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55866095",
   "metadata": {},
   "source": [
    "# Definición de emociones a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f836ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"] #Nombre para las clases\n",
    "Archives = [\"angry\",\"disgust\",\"fear\",\"happy\",\"sad\",\"surprise\"]\n",
    "#Las clases serán resectivamente: enojo=0, disgusto=1, miedo=2, felicidad=3, tristeza=4, sorpresa=5\n",
    "\n",
    "Datadirectory = \"train/\" #Para saber de donde se van a traer los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60daf441",
   "metadata": {},
   "source": [
    "# Obtención del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc749b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "training_Data = []\n",
    "\n",
    "#Se accede a cada uno de las carpetas para entrenar cada clase\n",
    "for category in Classes:\n",
    "    path = os.path.join(Datadirectory, category)\n",
    "    class_num = Classes.index(category)\n",
    "    j = 0\n",
    "    for img in os.listdir(path):\n",
    "        if j < 400:\n",
    "            j+=1\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            training_Data.append([new_array,class_num])\n",
    "\n",
    "#Desordena para que no haya problemas\n",
    "random.shuffle(training_Data)\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#Agrega en un solo\n",
    "\n",
    "for features,labels in training_Data:\n",
    "  X.append(features)\n",
    "  Y.append(labels)\n",
    "Y = np.array(Y)\n",
    "X = np.array(X).reshape(-1,img_size,img_size,3)\n",
    "\n",
    "#Se normalizan los datos, cuyo valor máximo es 255 (escala de grises)\n",
    "X = X / 255.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1dd625",
   "metadata": {},
   "source": [
    "# Se genera el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b14762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga un modelo diseño\n",
    "model = tf.keras.applications.MobileNetV2()\n",
    "\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[-2].output\n",
    "final_output = layers.Dense(128)(base_output)\n",
    "final_ouput = layers.Activation('relu')(final_output)\n",
    "final_output = layers.Dense(64)(final_output)\n",
    "final_ouput = layers.Activation('relu')(final_output)\n",
    "final_output = layers.Dense(6,activation='softmax')(final_output)\n",
    "\n",
    "modelo_caras = keras.Model(inputs = base_input, outputs = final_output)\n",
    "\n",
    "modelo_caras.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "#si se quiere visualizar el modelo final\n",
    "#modelo_caras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8138e",
   "metadata": {},
   "source": [
    "# Se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d558cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 55s 704ms/step - loss: 1.6875 - accuracy: 0.3746\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 1.1584 - accuracy: 0.5567\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 0.9841 - accuracy: 0.6288\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 0.8006 - accuracy: 0.6908\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 53s 704ms/step - loss: 0.7033 - accuracy: 0.7317\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 53s 702ms/step - loss: 0.6128 - accuracy: 0.7825\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 53s 700ms/step - loss: 0.5258 - accuracy: 0.8050\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 0.4149 - accuracy: 0.8529\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 53s 705ms/step - loss: 0.4225 - accuracy: 0.8558\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 53s 709ms/step - loss: 0.3037 - accuracy: 0.8929\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 0.2989 - accuracy: 0.8950\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 53s 703ms/step - loss: 0.2974 - accuracy: 0.8983\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 53s 700ms/step - loss: 0.2113 - accuracy: 0.9292\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 53s 705ms/step - loss: 0.2025 - accuracy: 0.9312\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 53s 705ms/step - loss: 0.2642 - accuracy: 0.9038\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 53s 702ms/step - loss: 0.1894 - accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 53s 704ms/step - loss: 0.1978 - accuracy: 0.9279\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 53s 702ms/step - loss: 0.1672 - accuracy: 0.9475\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 53s 705ms/step - loss: 0.1972 - accuracy: 0.9304\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 53s 704ms/step - loss: 0.1352 - accuracy: 0.9521\n"
     ]
    }
   ],
   "source": [
    "hist = modelo_caras.fit(X,Y,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d20b5a",
   "metadata": {},
   "source": [
    "# Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70f090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 321ms/step\n",
      "[[1.0000000e+00 2.6598330e-16 2.2132438e-17 3.9089520e-16 2.2175371e-17\n",
      "  4.1378434e-09]]\n"
     ]
    }
   ],
   "source": [
    "P=cv2.imread(\"train/0/Training_3908.jpg\")\n",
    "P=cv2.resize(P,(224,224))\n",
    "P = np.expand_dims(P,axis=0)\n",
    "P = P/255.0\n",
    "\n",
    "prediccion=modelo_caras.predict(P) #Mayor valor es nuestra predicción\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2c22e",
   "metadata": {},
   "source": [
    "# Modelo TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ad0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9548408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir \"tflite_models\"\n",
    "\n",
    "#Path y nombre del modelo tflite\n",
    "\n",
    "TFLITE_MODEL = \"tflite_models/modelo_caras.tflite\"\n",
    "\n",
    "run_model = tf.function(lambda x : modelo_caras(x))\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
    ")\n",
    "\n",
    "#Conversión a tflite\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "converted_tflite_model = converter.convert()\n",
    "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ea5bb",
   "metadata": {},
   "source": [
    "# Carga modelo TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5dfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path y nombre del modelo tflite\n",
    "TFLITE_MODEL = \"tflite_models/modelo_caras.tflite\"\n",
    "\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
    "\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83810325",
   "metadata": {},
   "source": [
    "# Prueba TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4087000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 2.6598431e-16 2.2132269e-17 3.9089366e-16 2.2175200e-17\n",
      "  4.1378354e-09]]\n"
     ]
    }
   ],
   "source": [
    "#Se requiere que el elemento a predecir sea tipo float32\n",
    "img = np.float32(P)\n",
    "\n",
    "tflite_interpreter.set_tensor(input_details[0]['index'], img)\n",
    "tflite_interpreter.invoke()\n",
    "tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "print(tflite_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f13d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
